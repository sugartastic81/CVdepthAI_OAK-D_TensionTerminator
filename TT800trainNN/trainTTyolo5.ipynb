{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/Block-Tschain/ig-projekt-1-Tschaein/blob/main/trainTTyolo5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tension Terminator YOLO5 Transfer Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKgLZQQUJ7Co"
   },
   "source": [
    "## Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93jKRTRrJvOe"
   },
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "BASE_MODEL = \"yolov5m\"\n",
    "TRAIN_EPOCHS = 70\n",
    "TRAIN_SIZE = 320\n",
    "\n",
    "TT_PROJECTNAME = \"TensionTerminator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QGsR2ANKB8o"
   },
   "source": [
    "## Mount Google Drive to backup files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu2Va7WlJzmf"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "google_drive_target_folder = '/content/drive/My Drive/'+TT_PROJECTNAME+'/'\n",
    "# Check if the target folder exists in Google Drive, create if it doesn't\n",
    "if not os.path.exists(google_drive_target_folder):\n",
    "    os.makedirs(google_drive_target_folder)\n",
    "    print(f\"Created folder: {google_drive_target_folder}\")\n",
    "print(\"Google Drive Target Folder: \" + google_drive_target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIGeSZH0J20v"
   },
   "source": [
    "# Clone YoloV5 GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_krnEAz0YLnn"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install\n",
    "%cd ..\n",
    "\n",
    "import torch\n",
    "from yolov5 import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sip3rbXXKSI1"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlWcje6iKGiq"
   },
   "outputs": [],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-zlSzHsKL0K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "from google.colab import userdata, files\n",
    "from datetime import datetime\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVqpyKmDkdY2"
   },
   "source": [
    "### Load the data from roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbPY5u8gh3nJ"
   },
   "outputs": [],
   "source": [
    "secret_key = userdata.get('rb-key')\n",
    "\n",
    "rf = Roboflow(api_key=secret_key)\n",
    "project = rf.workspace(\"juzaworkspace-wzpkn\").project(\"tensionterminatordetectionv2\")\n",
    "dataset = project.version(5).download(\"yolov5\")\n",
    "\n",
    "DATASET_DIR = dataset.location\n",
    "DATA_YAML = DATASET_DIR + \"/data.yaml\"\n",
    "print(\"\\n\\info\")\n",
    "print(\"Data saved to: \" + DATASET_DIR)\n",
    "print(\"Data YAML: \" + DATA_YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8WvuePgKweT"
   },
   "outputs": [],
   "source": [
    "# corrects the folders in the data.yaml\n",
    "\n",
    "# Path to the YAML file\n",
    "yaml_file_path = DATASET_DIR + 'data.yaml'\n",
    "\n",
    "# Read the YAML file\n",
    "with open(DATA_YAML) as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# Update the paths\n",
    "data['train'] = DATASET_DIR + '/train/images'\n",
    "data['val'] = DATASET_DIR + '/valid/images'\n",
    "data['test'] = DATASET_DIR + '/test/images'\n",
    "\n",
    "# Write the updated data back to the YAML file\n",
    "with open(DATA_YAML, 'w') as file:\n",
    "    yaml.dump(data, file)\n",
    "\n",
    "print(\"Updated data.yaml successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3ynDn37j3AQ"
   },
   "source": [
    "### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZAx8ZsaLeCZ"
   },
   "outputs": [],
   "source": [
    "model_training_command = \"python ./train.py --img \" + str(TRAIN_SIZE) + \" --batch 8 --epochs \" + str(TRAIN_EPOCHS) + \" --data \" + DATA_YAML + \" --weights \" + BASE_MODEL + \".pt --cache\"\n",
    "print(model_training_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GKG3jWaakdY2"
   },
   "outputs": [],
   "source": [
    "%cd /content/yolov5\n",
    "!{model_training_command}\n",
    "#!python ./train.py --img 640 --batch 8 --epochs 100 --data ./OverheadPersonDetection-3/data.yaml --weights yolov5m.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKANDueRj-j2"
   },
   "source": [
    "### Download the trained weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jMbRnf_sMEF2"
   },
   "outputs": [],
   "source": [
    "# Get latest run dir\n",
    "base_dir = '/content/runs/detect'\n",
    "latest_run_dir = max([os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))], key=os.path.getmtime)\n",
    "print(latest_run_dir)\n",
    "\n",
    "# modify if there is an error\n",
    "#latest_run_dir = \"/content/runs/detect/train3\"\n",
    "\n",
    "# Define the base directory where the runs are stored\n",
    "TRAINED_WEIGHTS = latest_run_dir + \"/weights/\" + \"best.pt\"\n",
    "\n",
    "# Construct the path to the best weights file\n",
    "print(\"Original trained weights path: \", TRAINED_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2YdQufk-nGJG"
   },
   "outputs": [],
   "source": [
    "# Get the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Construct the new file name with timestamp\n",
    "new_file_name = f\"TTmodel2_{BASE_MODEL}_img{TRAIN_SIZE}_{timestamp}.pt\"\n",
    "new_file_path = os.path.join(latest_run_dir, 'weights', new_file_name)\n",
    "\n",
    "# Copy the file with timestamp in the same directory\n",
    "shutil.copy2(TRAINED_WEIGHTS, new_file_path)\n",
    "print(\"New file path with timestamp: \", new_file_path)\n",
    "\n",
    "# Make sure the target folder exists\n",
    "if not os.path.exists(google_drive_target_folder):\n",
    "    os.makedirs(google_drive_target_folder)\n",
    "\n",
    "# Construct the target file path in Google Drive\n",
    "google_drive_target_path = os.path.join(google_drive_target_folder, new_file_name)\n",
    "\n",
    "# Copy the file to Google Drive\n",
    "shutil.copy2(new_file_path, google_drive_target_path)\n",
    "print(\"Model file copied to Google Drive: \", google_drive_target_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
